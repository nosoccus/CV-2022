{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4rK5TiNo_FGr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import concatenate\n",
        "from keras.layers import Input, Conv2D, BatchNormalization, MaxPool2D, MaxPooling2D, Activation, Flatten, Dense, Dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "data_train = pd.read_csv('./fashion-mnist_train.csv')\n",
        "X_full = data_train.iloc[:,1:]\n",
        "y_full = data_train.iloc[:,:1]\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_full, y_full, test_size = 0.2)"
      ],
      "metadata": {
        "id": "MKxSGyJECAOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.values.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
        "x_test = x_test.values.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
        "y_train = y_train.values.astype('int')\n",
        "y_test = y_test.values.astype('int')\n",
        "\n",
        "print('Training', x_train.shape, x_train.max())\n",
        "print('Testing', x_test.shape, x_test.max())"
      ],
      "metadata": {
        "id": "6bSA30TdLBot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reorganize by groups\n",
        "train_groups = [x_train[np.where(y_train==i)[0]] for i in np.unique(y_train)]\n",
        "test_groups = [x_test[np.where(y_test==i)[0]] for i in np.unique(y_train)]\n",
        "print('train groups:', [x.shape[0] for x in train_groups])\n",
        "print('test groups:', [x.shape[0] for x in test_groups])"
      ],
      "metadata": {
        "id": "ssLbTWMfLBl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_random_batch(in_groups, batch_halfsize=8):\n",
        "    out_img_a, out_img_b, out_score = [], [], []\n",
        "    all_groups = list(range(len(in_groups)))\n",
        "    for match_group in [True, False]:\n",
        "        group_idx = np.random.choice(all_groups, size=batch_halfsize)\n",
        "        out_img_a += [in_groups[c_idx][np.random.choice(range(in_groups[c_idx].shape[0]))] for c_idx in group_idx]\n",
        "        if match_group:\n",
        "            b_group_idx = group_idx\n",
        "            out_score += [1]*batch_halfsize\n",
        "        else:\n",
        "            # anything but the same group\n",
        "            non_group_idx = [np.random.choice([i for i in all_groups if i != c_idx]) for c_idx in group_idx]\n",
        "            b_group_idx = non_group_idx\n",
        "            out_score += [0]*batch_halfsize\n",
        "        out_img_b += [in_groups[c_idx][np.random.choice(range(in_groups[c_idx].shape[0]))] for c_idx in b_group_idx]\n",
        "    return np.stack(out_img_a,0), np.stack(out_img_b,0), np.stack(out_score,0)"
      ],
      "metadata": {
        "id": "5q3VVZJgLBi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pv_a, pv_b, pv_sim = gen_random_batch(train_groups, 3)\n",
        "fig, m_axs = plt.subplots(2, pv_a.shape[0], figsize=(12, 6))\n",
        "for c_a, c_b, c_d, (ax1, ax2) in zip(pv_a, pv_b, pv_sim, m_axs.T):\n",
        "    ax1.imshow(c_a[:,:,0])\n",
        "    ax1.set_title('Image A')\n",
        "    ax1.axis('off')\n",
        "    ax2.imshow(c_b[:,:,0])\n",
        "    ax2.set_title('Image B\\n Similarity: %3.0f%%' % (100*c_d))\n",
        "    ax2.axis('off')"
      ],
      "metadata": {
        "id": "EUgEyNPwLBf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_in = Input(shape=x_train.shape[1:], name='InceptionV1Input')\n",
        "n_layer = img_in\n",
        "\n",
        "layer_1 = Conv2D(64, (1,1), padding='same', activation='relu')(n_layer)\n",
        "layer_1 = Conv2D(64, (3,3), padding='same', activation='relu')(layer_1)\n",
        "layer_2 = Conv2D(64, (1,1), padding='same', activation='relu')(n_layer)\n",
        "layer_2 = Conv2D(64, (5,5), padding='same', activation='relu')(layer_2)\n",
        "layer_3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(n_layer)\n",
        "layer_3 = Conv2D(64, (1,1), padding='same', activation='relu')(layer_3)\n",
        "\n",
        "output = keras.layers.concatenate([layer_1, layer_2, layer_3], axis = 3)\n",
        "output = Flatten()(output)\n",
        "out = Dense(10, activation='relu')(output)\n",
        "\n",
        "feature_model = Model(inputs=[img_in], outputs=[out], name='InceptionV1Model')\n",
        "feature_model.summary()"
      ],
      "metadata": {
        "id": "Zx4mJCj6LBbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_a_in = Input(shape=x_train.shape[1:], name='ImageA_Input')\n",
        "img_b_in = Input(shape=x_train.shape[1:], name='ImageB_Input')\n",
        "img_a_feat = feature_model(img_a_in)\n",
        "img_b_feat = feature_model(img_b_in)\n",
        "combined_features = concatenate([img_a_feat, img_b_feat], name='merge_features')\n",
        "combined_features = Dense(16, activation='linear')(combined_features)\n",
        "combined_features = BatchNormalization()(combined_features)\n",
        "combined_features = Activation('relu')(combined_features)\n",
        "combined_features = Dense(4, activation='linear')(combined_features)\n",
        "combined_features = BatchNormalization()(combined_features)\n",
        "combined_features = Activation('relu')(combined_features)\n",
        "combined_features = Dense(1, activation='sigmoid')(combined_features)\n",
        "similarity_model = Model(inputs=[img_a_in, img_b_in], outputs=[combined_features], name='Similarity_Model')\n",
        "similarity_model.summary()"
      ],
      "metadata": {
        "id": "IyKA9yT8LO2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup the optimization process\n",
        "similarity_model.compile(optimizer='adam', loss = 'binary_crossentropy',\n",
        "metrics = ['mae'])"
      ],
      "metadata": {
        "id": "H9_0mozOLOzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_model_output(nb_examples = 3):\n",
        "    pv_a, pv_b, pv_sim = gen_random_batch(test_groups, nb_examples)\n",
        "    pred_sim = similarity_model.predict([pv_a, pv_b])\n",
        "    fig, m_axs = plt.subplots(2, pv_a.shape[0], figsize = (12, 6))\n",
        "    for c_a, c_b, c_d, p_d, (ax1, ax2) in zip(pv_a, pv_b, pv_sim, pred_sim,m_axs.T):\n",
        "        ax1.imshow(c_a[:,:,0])\n",
        "        ax1.set_title('Image A\\n Actual: %3.0f%%' % (100*c_d))\n",
        "        ax1.axis('off')\n",
        "        ax2.imshow(c_b[:,:,0])\n",
        "        ax2.set_title('Image B\\n Predicted: %3.0f%%' % (100*p_d))\n",
        "        ax2.axis('off')\n",
        "    return fig\n",
        "# a completely untrained model\n",
        "_ = show_model_output()"
      ],
      "metadata": {
        "id": "JSej5nd6LOxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a generator out of the data\n",
        "def siam_gen(in_groups, batch_size = 32):\n",
        "    while True:\n",
        "        pv_a, pv_b, pv_sim = gen_random_batch(in_groups, batch_size//2)\n",
        "        yield [pv_a, pv_b], pv_sim\n",
        "# we want a constant validation group to have a frame of reference for model performance\n",
        "valid_a, valid_b, valid_sim = gen_random_batch(test_groups, 1024)\n",
        "loss_history = similarity_model.fit_generator(siam_gen(train_groups),\n",
        "                                              steps_per_epoch = 500,\n",
        "                                              validation_data=([valid_a, valid_b],valid_sim),\n",
        "                                            epochs = 10,\n",
        "                                            verbose = True)"
      ],
      "metadata": {
        "id": "J_1o7h6kLOuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = show_model_output()"
      ],
      "metadata": {
        "id": "6IGnefQgLXtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_shirt_vec = np.stack([train_groups[0][0]]*x_test.shape[0],0)\n",
        "t_shirt_score = similarity_model.predict([t_shirt_vec, x_test], verbose=True, batch_size=128)\n",
        "ankle_boot_vec = np.stack([train_groups[-1][0]]*x_test.shape[0],0)\n",
        "ankle_boot_score = similarity_model.predict([ankle_boot_vec, x_test], verbose=True, batch_size=128)"
      ],
      "metadata": {
        "id": "zOO_o_gaLXmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj_categories = [\n",
        "    'T-shirt/top','Trouser','Pullover','Dress',\n",
        "    'Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot'\n",
        "]\n",
        "\n",
        "colors = plt.cm.rainbow(np.linspace(0, 1, 10))\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for c_group, (c_color, c_label) in enumerate(zip(colors, obj_categories)):\n",
        "    plt.scatter(\n",
        "        t_shirt_score[np.where(y_test == c_group), 0],\n",
        "        ankle_boot_score[np.where(y_test == c_group), 0],\n",
        "        marker='.',\n",
        "        color=c_color,\n",
        "        linewidth=1,\n",
        "        alpha=0.8,\n",
        "        label=c_label\n",
        "    )\n",
        "    \n",
        "plt.xlabel('T-Shirt Dimension')\n",
        "plt.ylabel('Ankle-Boot Dimension')\n",
        "plt.title('T-Shirt and Ankle-Boot Dimension')\n",
        "plt.legend(loc='best')\n",
        "plt.savefig('tshirt-boot-dist.png')\n",
        "plt.show(block=False)"
      ],
      "metadata": {
        "id": "1HEdSg2fLXim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_features = feature_model.predict(x_test, verbose = True,batch_size=128)"
      ],
      "metadata": {
        "id": "XVqMI-GlLbSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.manifold import TSNE\n",
        "tsne_obj = TSNE(n_components=2,\n",
        "            init='pca',\n",
        "            random_state=101,\n",
        "            method='barnes_hut',\n",
        "            n_iter=500,\n",
        "            verbose=2)\n",
        "tsne_features = tsne_obj.fit_transform(x_test_features)"
      ],
      "metadata": {
        "id": "EGg7rKHCLbOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj_categories = ['T-shirt/top','Trouser','Pullover','Dress',\n",
        "'Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot'\n",
        "]\n",
        "\n",
        "colors = plt.cm.rainbow(np.linspace(0, 1, 10))\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for c_group, (c_color, c_label) in enumerate(zip(colors, obj_categories)):\n",
        "    plt.scatter(tsne_features[np.where(y_test == c_group), 0],\n",
        "        tsne_features[np.where(y_test == c_group), 1],\n",
        "        marker='o',\n",
        "        color=c_color,\n",
        "        linewidth=1,\n",
        "        alpha=0.8,\n",
        "        label=c_label)\n",
        "    \n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "plt.title('t-SNE on Testing Samples')\n",
        "plt.legend(loc='best')\n",
        "plt.savefig('clothes-dist.png')\n",
        "plt.show(block=False)"
      ],
      "metadata": {
        "id": "JQ1urdsbLmTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pjeJ18TdLmQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-SaJdk6SLmNM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}